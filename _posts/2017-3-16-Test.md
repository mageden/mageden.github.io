---
layout: post
title: "Data cleaning: Driving Simulator Data"
categories: cleaning
---

This is the first post in a short series of examples for cleaning data files using R. One of the major reasons that I switched from SPSS to R was due to the difficulty and time-consumption that was involved in cleaning driving simulator data files. After drudging through ~25 participants worth of data manually in Excel, I decided it was time to join the modern age. As I started to learn R, I found that while there was an abundance of data cleaning tips, there weren't many examples of people working through a problem. The goal of this post, and the others in the series, will be to provide moderately detailed examples of how to use R for data cleaning, with the hopes of helping newer R-chitects out there. I am still improving myself, so I am sure there are better ways to do than what I did, however coding is always a learning process, and seeing how others solve problems can be helpful regardless.

## Data description

The data we will be going through here is from the STISIM driving simulator, and was collected during an experiment investigating the impact of mind wandering, or task-unrelated thoughts, on individual's driving performance. Individual's thought states were measured using an intermittant auditory probe, in which participant's would be asked to report whether they were engaging in task-related or task-unrelated thoughts. This response was then paired with the data from 0-15 seconds prior to the probe.

As there is a substantial amount of cleaning requried for this data, I have decided to only display up until the probe responses have been associated with the correct interval. While there were more steps involved afterward they are less intersting and so were not included here.

## Reading in the Data

The first step is specifying the directory that the datafiles are located, extracting their names, and then loading them into R. In order to do this I have written a short function which can have multiple folders specified (as long as their inputted as a string), a string to search files in that directory for, and an operator for dealing with multiple strings. While most of these operations aren't used here, I have found them to be needed often enough in my work to have included them in the function.


```r
raw_paths <- function(foldername, string, operator = "OR") {
    foldername <- sapply(foldername, function(x) {
        protection <- sapply(strsplit(as.character(x), ""), tail, 1)
        if (protection != "/") {
            foldername <- paste0(foldername, "/")
        } else {
            foldername <- foldername
        }
    })
    if (missing(string)) {
        files <- sapply(foldername, function(x) {
            allfilesn <- list.files(x)
            paste0(rep(x, length(allfilesn)), allfilesn)
        })
        return(unname(unlist(files)))
    } else {
        allfiles <- list.files(foldername)
        if (operator == "AND") {
            reformat <- sapply(string, function(x) {paste0("(?=.*", x, ")")})
            and.string <- paste(reformat, collapse = "")
            wantedfiles <- allfiles[grep(and.string, allfiles, perl = TRUE)]
        }
        if (operator == "OR") {
            wantedfiles <- allfiles[grep(paste(string, collapse = "|"), allfiles)]
        }
        files <- paste0(rep(foldername, length(wantedfiles)), wantedfiles)
        return(files)
    }
}
```

Now that we have the function, this process is made quite easy. It is important to note that the filenames will be provided to relative to the location of the source file if it is being sourced, or the working directory if it is in the console.


```r
directory <- "../data/raw/new/"  
rawfiles <- raw_paths(directory)
```

The file names look good, so next I start reading in the data files. The easiest way I have found to do this is to first read in each datafile individually, do some minor cleaning so that they can merge together, and then combine them. Here I use lapply to do this, as we create a list of dataframes from our list of filenames. Before jumping in we need to take a look at the structure of the datafiles. In this case, each file's data is preceeded by 130 lines of information summarizing the scenario. As we aren't interested in these summary statistics, we tell the read.table function to skip these lines. There is also some extra summary information at the end that we are not interested in, so we will want to cut that out too.


```r
datalist <- lapply(rawfiles, function(x) {                       
    file <- read.table(x,                                        
                       sep = "",                                 
                       header = FALSE,
                       na.strings = "",
                       stringsAsFactors = FALSE,
                       skip = 130,
                       fill = TRUE)
    file$ID <- gsub("[^0-9]", "", x)
    file$cond <- ifelse((grepl("C_", x) == 1), "low", "high")
    trashatend <- apply(file, 1, function(x) {sum(is.na(x))})
    trashatend <- which(trashatend > 1)[1] - 1
    file <- file[1:trashatend, ]
    return(file)
    }
)
```

Now that we have each file with the same dimensions, and some of the junk removed, lets add them together, fix some variable types, and take a look.


```r
alldata <- do.call("rbind", datalist)
alldata[1:13] <- sapply(alldata[1:13], as.numeric)
```

|    V1  |   V2  |    V3   |   V4   |   V5  |    V6  |   V7  | V8 |  V9  |   V10  |   V11 |    V12  | V13 | ID |  cond |
|------ | ----- | ------ | ------ | ------ | ------ | ----- | --- | --- | ------ | ------ | ------ | ------ | --- | -----|
| 6.017 |  6.26  | -0.01 |  23.18 |  -0.03 |  47.15 |  6.06 |   1 |   1 |  15.80 |  29503 |  64892 |  0.012 | 10 |  low  
| 6.117 |  6.25  | -0.02 | 23.80  | -0.03  | 49.51  | 6.06  |  1  |  1  | 16.23  | 29503  | 64892  | 0.016 | 10  | low  
| 6.217 |  6.23  | -0.02 | 24.43  | -0.03  | 51.93  | 6.06  |  1  |  1  | 16.65  | 29503  | 64892  | 0.022 | 10   | low  
| 6.317 |  6.21  | -0.03 |  25.05 |  -0.03 |  54.42 |  6.06 |   1 |   1 |  17.08 |  29503 |  64892 |  0.025 | 10  | low  
| 6.417 |  6.20  | -0.03 |  25.67 |  -0.02 |  56.96 |  6.07 |   1 |   1 |  17.50 |  29503 |  64892  | 0.030 | 10  | low  
| 6.517 |  6.18  | -0.03 |  26.29 |  -0.02 |  59.57 |  6.07 |   1 |   1 |  17.92 |  29503 |  64892 |  0.035 | 10  | low  

## Cleaning the data

### Marking mind wandering

One of the tricky things that I deal with is associating an individual's response to a mind wandering probe to the interval in which they were mind wandering. For example, if a probe occurs at 45 seconds, the individual may respond sometime around 48 seconds. Their response (lets say mind wandering here) is then associated with their performance data for the 15 second interval prior to the probe (29-44s). In order to do this, first I mark the times at which the mind wandering probes were presented.


```r
mwprobes <- data.frame(
    low_probe_times = c(40, 69, 110, 158, 193, 285, 361,
                        452, 489, 576, 656, 686, 757, 811, 899),
    high_probe_times = c(68, 144, 233, 280, 315, 354, 398,
                         446, 482, 528, 583, 652, 739, 814, 899)
)
```

Next, I make a new variable to be used to represent people's probe response. Then, I set the new variable to be equal to one whenever the truncated time variable was equal to one of the probe times. The values were truncated as the simulator collects data every 10th of a second. Since I only want the first value, the one closest to the original time of the probe, I set all values in which the current value is repeated to be equal to NA, removing duplicates.


```r
alldata$probe.temp <- NA
alldata$probe.temp[alldata$cond == "low" & trunc(alldata$V1) %in% mwprobes$low_probe_times] <- 1
alldata$probe.temp[alldata$cond == "high" & trunc(alldata$V1) %in% mwprobes$high_probe_times] <- 1
alldata$probe.temp[c(T, diff(alldata$probe.temp) == 0)] <- NA
```

Now I want to identify the response to the mind wandering probe. V8 and V9 represent two buttons that participants were provided, and when a probe occured they were asked to hit the on-task button (V8) or mind wandering button (V9). The response to these buttons was per a 10th of a second, so similar to above I needed only the data from the first moment of the response, and none of the redundant response within that probe. For example, if an individual pressed the button for half a second, there would be five rows displaying their response. Since I am only interested in which response they had, the redundant data is removed.


```r
mark.probe <- function(data, character) {
    data[c(T, diff(data) == 0)] <- NA
    data <- ifelse(data == 0, character, NA)
}
TRT <- mark.probe(alldata$V8, "OT")
TUT <- mark.probe(alldata$V9, "MW")

alldata$mwresp.temp <- NA
alldata$mwresp.temp[!is.na(TRT)] <- TRT[!is.na(TRT)]
alldata$mwresp.temp[!is.na(TUT)] <- TUT[!is.na(TUT)]
```

Alright now for the tricky bit. Next I associated their response to the mind wandering probe to the time stamp that we used in our earlier temporary variable. Then, once that is paired, the probe response is associated with a period for 15 seconds prior to the probes presentation. In order to do this, I first split the file into a list of files by ID, and add in an arbitrary amount of time to the high load condition in order to ensure that time stamps with the low load and high load conditions can't interfere with each other. Following this, the files are then recombined.  


```r
# Pairs mind wandering response to time stampe of probe
pair.mw.to.probe <- function(probe, mwresp, time, range = 15) {
    # Indicators
    p.ind <- which(!is.na(probe))
    mw.ind <- which(!is.na(mwresp))
    # Time stamp of indicators
    t.p.ind <- time[p.ind]
    t.mw.ind <- time[mw.ind]
    # Apply to range of values
    z <- sapply(t.p.ind, function(x) {
        x <- na.omit(mwresp[(time >= x & time <= (x + range))])
        x[length(x)] # Returns the last item if more than one result occurs
    }
    )
    associated <- rep(NA, length(probe))
    associated[p.ind] <- z
    return(associated)
}

# Associates mind wandering response for previous 15 seconds worth of data
associate_rows <- function(vector, time, lag = 15) {
    values <- which(!is.na(vector))
    want <- rep(NA, length(vector))
    for (i in values) {
        start <- time[i] - lag
        end <- time[i]
        want[time > start & time < end] <- vector[i]
    }
    return(want)
}


# Add 2000 seconds to the high condition so they are different
alldata$time.temp <- alldata$V1
alldata$time.temp[alldata$cond == "high"] <- alldata$V1[alldata$cond == "high"] + 2000

# Split into list of dataframes by ID to avoid time stamp redundancies
templist <- split(alldata, alldata$ID)

# Pairing mind wandering response to probe time
templist2 <- lapply(templist, function(x) {
    z <- pair.mw.to.probe(x$probe.temp, x$mwresp.temp, x$time.temp)
    x$mwresp.probe.temp <- z
    x
    }
)

# Number probes
templist3 <- lapply(templist2, function(x) {
    ## Number all probes
    # Rename probe
    ind <- which(!is.na(x$probe.temp))
    x$probe.num <- x$probe.temp
    x$probe.num[ind] <- 1:length(ind)
    # Back associate
    z1 = associate_rows(vector = x$probe.num,
                       time = x$time.temp,
                       lag = 16)
    x$probe.num = z1
    ## Number by condition
    # Rename probe
    ind.high <- which(!is.na(x$probe.temp) & x$cond == "high")
    #print(ind.high)
    ind.low <- which(!is.na(x$probe.temp) & x$cond == "low")
    x$probe.num.cond <- x$probe.temp
    x$probe.num.cond[ind.high] <- 1:length(ind.high)
    x$probe.num.cond[ind.low] <- 1:length(ind.low)
    # Back associate
    z2 = associate_rows(vector = x$probe.num.cond,
                        time = x$time.temp,
                        lag = 16)
    x$probe.num.cond = z2
    x
})

# Associate mind wandering response with previous 15 seconds data
    # Lag = 16 since trunc removes 15 otherwise
finallist <- lapply(templist3, function(x) {
    z = associate_rows(vector = x$mwresp.probe.temp,
                       time = x$time.temp,
                       lag = 16)
    x$mwresp = z
    x
    }
)

# Merge dataframes
#alldata <- do.call("rbind", finallist)
alldata <- plyr::rbind.fill(finallist)
# Remove column V8 and V9
alldata[c("V8", "V9")] <- NULL
```

## Concluding Remarks

Some details were glossed over here to keep the post short, but hopefully everything that is needed is present. Future posts will follow in the structure of this one displaying how to solve particular data cleaning issues that I have had.
